{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1S8qpFd0ycnbVuU86/mqM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patanjali-b/Lesk_WSD/blob/main/POS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install conllu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKf-yHntuauh",
        "outputId": "85947b15-d7c9-423b-c245-20745cb48a29"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: conllu in /usr/local/lib/python3.9/dist-packages (4.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RZEcsBz8sgWC"
      },
      "outputs": [],
      "source": [
        "import conllu\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "# from 'dataset.py' import POSTaggingDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ],
      "metadata": {
        "id": "kQssoYe7sjxv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/en_atis-ud-train.conllu', 'r', encoding=\"utf-8\") as f:\n",
        "    sentences = conllu.parse(f.read())\n",
        "\n",
        "    train_data = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        indexes = []\n",
        "        words = []\n",
        "        pos = []\n",
        "        # print(sentence)\n",
        "        for i in range(len(sentence)):\n",
        "            indexes.append(sentence[i]['id'])\n",
        "            words.append(sentence[i]['form'])\n",
        "            pos.append(sentence[i]['upos'])\n",
        "        tagged_sentence = (words, pos)\n",
        "        train_data.append(tagged_sentence)\n",
        "print(train_data[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dML28zBsoi6",
        "outputId": "c4b677c5-3136-4836-c3d0-ecf4fcb100de"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['what', 'is', 'the', 'cost', 'of', 'a', 'round', 'trip', 'flight', 'from', 'pittsburgh', 'to', 'atlanta', 'beginning', 'on', 'april', 'twenty', 'fifth', 'and', 'returning', 'on', 'may', 'sixth'], ['PRON', 'AUX', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', 'NOUN', 'ADP', 'PROPN', 'ADP', 'PROPN', 'VERB', 'ADP', 'NOUN', 'NUM', 'ADJ', 'CCONJ', 'VERB', 'ADP', 'NOUN', 'ADJ'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_to_idx = {\n",
        "    \"ADJ\": 0,\n",
        "    \"ADP\": 1,\n",
        "    \"ADV\": 2,\n",
        "    \"AUX\": 3,\n",
        "    \"CCONJ\": 4,\n",
        "    \"DET\": 5,\n",
        "    \"INTJ\": 6,\n",
        "    \"NOUN\": 7,\n",
        "    \"NUM\": 8,\n",
        "    \"PART\": 9,\n",
        "    \"PRON\": 10,\n",
        "    \"PROPN\": 11,\n",
        "    \"PUNCT\": 12,\n",
        "    \"SCONJ\": 13,\n",
        "    \"SYM\": 14,\n",
        "    \"VERB\": 15,\n",
        "    \"X\": 16,\n",
        "    \"UNK\":17\n",
        "}\n",
        "\n",
        "tagset_size = len(tag_to_idx)\n",
        "\n"
      ],
      "metadata": {
        "id": "8Awfp5EEstcv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_idx = {}\n",
        "for sentence, tags in train_data:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_idx:\n",
        "            word_to_idx[word] = len(word_to_idx)\n",
        "word_to_idx[\"UNK\"] = len(word_to_idx)\n",
        "vocab_size = len(word_to_idx)\n"
      ],
      "metadata": {
        "id": "yZkxalFNszrG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "7eDKMTWYs3Ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 300\n",
        "hidden_dim = 300\n",
        "\n",
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "        self.hidden = self.init_hidden()\n",
        "    def init_hidden(self):\n",
        "      return (torch.zeros(1,1,self.hidden_dim), torch.zeros(1,1,self.hidden_dim))\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "metadata": {
        "id": "IPNuZbbUs6jY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMTagger(embedding_dim, hidden_dim, vocab_size, tagset_size).to(device)\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)   \n",
        "\n",
        "def input_seq(sentence, word_to_idx):\n",
        "    idxs = []\n",
        "    for w in sentence:\n",
        "          if w in word_to_idx:\n",
        "                idxs.append(word_to_idx[w])\n",
        "          if w not in word_to_idx:\n",
        "                idxs.append(word_to_idx[\"UNK\"])\n",
        "\n",
        "\n",
        "    # length = len(sentence)\n",
        "    # if(length < 46):\n",
        "    #   while(46-length >0 and flag == 1):\n",
        "    #     idxs.append(len(word_to_idx))\n",
        "    #   while(46-length >0 and flag == 0):\n",
        "    #     idxs.append(len(tag_to_idx))      \n",
        "        \n",
        "    return torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "\n",
        "for epoch in range(15): \n",
        "    print(\"Epoch: \", epoch)\n",
        "    print(\"Device type = \", device)\n",
        "    for sentence, tags in train_data:\n",
        "        model.zero_grad()\n",
        "        model.hidden = model.init_hidden()\n",
        "        input_sentence = input_seq(sentence, word_to_idx)\n",
        "        targets = input_seq(tags, tag_to_idx)\n",
        "\n",
        "        tag_scores = model(input_sentence).to(device)\n",
        "\n",
        "        loss = loss_function(tag_scores, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Loss: \", loss.item())\n",
        "    #calculate accuracy\n",
        "    correct_counts = 0\n",
        "    total_counts = 0\n",
        "    with torch.no_grad():\n",
        "        for sentence, tags in train_data:\n",
        "            input_sentence = input_seq(sentence, word_to_idx)\n",
        "            targets = input_seq(tags, tag_to_idx)\n",
        "            tag_scores = model(input_sentence).to(device)\n",
        "            #print(\"Tag scores = \", len(tag_scores))\n",
        "            for i in range(len(tag_scores)):\n",
        "                predicted_index = torch.argmax(tag_scores[i])\n",
        "                if predicted_index == targets[i]:\n",
        "                    correct_counts += 1\n",
        "                total_counts += 1\n",
        "        print(\"Training Accuracy = \", correct_counts/total_counts)\n",
        "        \n",
        "\n",
        "# torch.save(model.state_dict(), \"model.pt\")\n",
        "\n",
        "\"\"\"# TEST THE MODEL\"\"\"\n",
        "\n",
        "\n",
        "# torch.load(\"model.pt\")\n",
        "# model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UrC52IhKs_eD",
        "outputId": "cb6585a6-26e2-4b47-fb56-a04387b9d029"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0\n",
            "Device type =  cpu\n",
            "Loss:  0.0005204427870921791\n",
            "Training Accuracy =  0.9540232247456583\n",
            "Epoch:  1\n",
            "Device type =  cpu\n",
            "Loss:  0.00019949952547904104\n",
            "Training Accuracy =  0.9632514643921488\n",
            "Epoch:  2\n",
            "Device type =  cpu\n",
            "Loss:  0.00012994921416975558\n",
            "Training Accuracy =  0.9658411262974\n",
            "Epoch:  3\n",
            "Device type =  cpu\n",
            "Loss:  0.00011509454634506255\n",
            "Training Accuracy =  0.9666015825711644\n",
            "Epoch:  4\n",
            "Device type =  cpu\n",
            "Loss:  9.526610665488988e-05\n",
            "Training Accuracy =  0.9674031445894564\n",
            "Epoch:  5\n",
            "Device type =  cpu\n",
            "Loss:  7.904250378487632e-05\n",
            "Training Accuracy =  0.9680608365019011\n",
            "Epoch:  6\n",
            "Device type =  cpu\n",
            "Loss:  7.028233085293323e-05\n",
            "Training Accuracy =  0.9686363169252903\n",
            "Epoch:  7\n",
            "Device type =  cpu\n",
            "Loss:  6.024073081789538e-05\n",
            "Training Accuracy =  0.968903504264721\n",
            "Epoch:  8\n",
            "Device type =  cpu\n",
            "Loss:  5.0422320782672614e-05\n",
            "Training Accuracy =  0.9690679272428322\n",
            "Epoch:  9\n",
            "Device type =  cpu\n",
            "Loss:  4.225747397867963e-05\n",
            "Training Accuracy =  0.9694995375603741\n",
            "Epoch:  10\n",
            "Device type =  cpu\n",
            "Loss:  3.608902989071794e-05\n",
            "Training Accuracy =  0.9699311478779159\n",
            "Epoch:  11\n",
            "Device type =  cpu\n",
            "Loss:  3.1142270017880946e-05\n",
            "Training Accuracy =  0.9704038639399856\n",
            "Epoch:  12\n",
            "Device type =  cpu\n",
            "Loss:  2.6925545171252452e-05\n",
            "Training Accuracy =  0.9708354742575275\n",
            "Epoch:  13\n",
            "Device type =  cpu\n",
            "Loss:  2.3260079615283757e-05\n",
            "Training Accuracy =  0.9710410029801665\n",
            "Epoch:  14\n",
            "Device type =  cpu\n",
            "Loss:  2.0175688405288383e-05\n",
            "Training Accuracy =  0.9712670845750694\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# TEST THE MODEL'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0O5kbmTht53X"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}